---
title: "writeup"
output: html_document
---

## Data Science 5620 --- Deliverable 10
### Central Limit Theorem
### Rastko Stojsin


## The Central Limit Theorem (CLT)
As sameple size increases, the distribution of sample means becomes approximatly normal more and more. The central limit theorem only applies when certain sample conidtions are met;
1. Independent observations
2. Identically distributed observations
3. Mean and variance exist
4. Sample size large enough for convergence

## Simulation Setup
In this simulation study, I am going to compare the sampling distribution of the mean generated by simulation to the sampling distribution implied by the central limit theorem. I will then compare the distributions graphically in QQ-plots.

This will be a 4 Ã— 4 factorial experiment. The first factor will be the sample size, with N = 5, 10, 20, and 40. The second factor will be the degree of skewness in the underlying distribution. The underlying distribution will be the Skew-Normal distribution. The Skew-Normal distribution has three parameters: location, scale, and slant. When the slant parameter is 0, the distribution reverts to the normal distribution. As the slant parameter increases, the distribution becomes increasingly skewed. In this simulation, slant will be set to 0, 2, 10, 100. Location and scale to 0 and 1, respectively, for all simulations.

The output of each combination of factors will be plotted by generating a sampling distribution of 5000 draws from both the CLT approximation and the simulation approximation. When analyzing data, the parameters for the mean and variance (in the case of the CLT shortcut) or the parameters for the distribution (in the case of MLE, MM, etc) are replaced with sample estimates. For the purposes of this simulation, I will treat the mean and variance as known values and use the actual population parameters and the population mean and variance instead of sample estimates.

```{r library, include = FALSE}
library(sn)
library(magrittr)
library(ggplot2)
```

```{r param_setup, include = FALSE}
R <- 5000
N <- 5
sla <- 10
loc <- 0
sca <- 1
```


```{r gen_plot_function, include = FALSE}
plot_gen <- function(N, sla) {
  helper <- sla / (sqrt(1 + sla ^ 2))
  pop_mean <- loc + sca * helper * sqrt(2 / pi)
  pop_sd <- sqrt(sca ^ 2 * (1 - (2 * helper ^ 2) / pi))
  
  Y <- rnorm(R)
  sample_dist_clt <-  Y * (pop_sd / sqrt(N)) + pop_mean
  ran_skew <-
    array(rsn(
      R * N,
      xi = loc,
      omega = sca,
      alpha = sla
    ), dim = c(R, N))
  sample_dist_sim <- apply(ran_skew, 1, mean)
  
  qqplot(
    sample_dist_sim,
    sample_dist_clt,
    asp = 0.5,
    axes = F,
    frame.plot = TRUE
  )
  abline(0, 1)
}
```

```{r plot_setup, include = FALSE}
plot_labs <- function(xfrac, yfrac, label, pos = 4, ...) {
  u <- par("usr")
  x <- u[1] + xfrac * (u[2] - u[1])
  y <- u[4] - yfrac * (u[4] - u[3])
  text(x, y, label, pos = pos, ...)
}
```



```{r plot_all }
par(mfrow = c(4, 5), mai = c(0.1, 0.1, 0.2, 0.1))
sla <- c(0, 2, 10, 100)
N <- c(5, 10, 20, 40)
x <- seq(-3, 3, by = 0.05)
sk_label <- c("slant = 0", "slant = 2", "slant = 10", "slant = 100")
  for (i in 1:length(sla)) {
  plot(
    dsn(
      x,
      xi = loc,
      omega = sca,
      alpha = sla[i]),
    type = 'l',
    axes = FALSE,
    ann = FALSE,
    frame.plot = TRUE)
  plot_labs(0.001, 0.07, sk_label[i])
  labels <- c("N = 5", "N = 10", "N = 20", "N = 40")
  for (j in 1:length(N)) {
    plot_gen(N[j], sla[i])
    plot_labs(0.02, 0.07, labels[j])}
}
```


## Conclusion



The deviation becomes more pronounced at the edges as the slant of the distribution increases. The deviation is also larger for small sample sizes - and smaller for high sample sizes! This means CLT can be used even when slant is present - especially with many samples! These simulations confirm the robustness for the CLT.
